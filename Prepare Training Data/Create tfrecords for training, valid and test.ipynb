{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tfrecords for train, valid and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "path_train_dataset = '/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/train_test_valid/all_events_train.json'\n",
    "path_valid_dataset = '/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/train_test_valid/all_events_valid.json'\n",
    "path_test_dataset = '/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/train_test_valid/all_events_test.json'\n",
    "\n",
    "df_train = pd.read_json(path_train_dataset)\n",
    "df_valid = pd.read_json(path_valid_dataset)\n",
    "df_test = pd.read_json(path_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impost dictionary to define padding\n",
    "dict_path = '/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/padded_arrays/pctl999_padlen_dict.json'\n",
    "# Save dict containing 99.9 pctl length of each event type for training data\n",
    "import json\n",
    "\n",
    "with open(dict_path) as filehandle:\n",
    "    pctl_999_dict = json.load(filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check Serialization to tf.example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize target and feature to single tf-record\n",
    "def serialize_example(target,target2, feature1, feature2,feature3,feature4, feature5,feature6,feature7,feature8,feature9):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "  \n",
    "  # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "  # data type.\n",
    "    feature = {\n",
    "      'HOSPITAL_EXPIRE_FLAG': tf.train.Feature(int64_list=tf.train.Int64List(value=[target])),\n",
    "      'LOS': tf.train.Feature(int64_list=tf.train.Int64List(value=[target2])),\n",
    "      'feature1': tf.train.Feature(int64_list=tf.train.Int64List(value=feature1)),\n",
    "      'feature2': tf.train.Feature(int64_list=tf.train.Int64List(value=feature2)),\n",
    "      'feature3': tf.train.Feature(int64_list=tf.train.Int64List(value=feature3)),\n",
    "      'feature4': tf.train.Feature(int64_list=tf.train.Int64List(value=feature4)),\n",
    "      'feature5': tf.train.Feature(int64_list=tf.train.Int64List(value=feature5)),\n",
    "      'feature6': tf.train.Feature(int64_list=tf.train.Int64List(value=feature6)),\n",
    "      'feature7': tf.train.Feature(int64_list=tf.train.Int64List(value=feature7)),\n",
    "      'feature8': tf.train.Feature(int64_list=tf.train.Int64List(value=feature8)),\n",
    "      'feature9': tf.train.Feature(int64_list=tf.train.Int64List(value=feature9))\n",
    "    }\n",
    "  \n",
    "  # Create a Features message using tf.train.Example\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to test\n",
    "serialized_example = serialize_example(target = df_train['HOSPITAL_EXPIRE_FLAG'][20],\n",
    "                                       target2 = df_train['LOS'][20],\n",
    "                                       feature1 = df_train['event'][20], \n",
    "                                       feature2 = df_train['inputevents_cv'][20],\n",
    "                                       feature3 = df_train['inputevents_mv'][20],\n",
    "                                       feature4 = df_train['labevents'][20], \n",
    "                                       feature5 = df_train['microbioevents'][20],\n",
    "                                       feature6 = df_train['noteevents'][20],\n",
    "                                       feature7 = df_train['outputevents'][20],\n",
    "                                       feature8 = df_train['prescriptionevents'][20],\n",
    "                                       feature9 = df_train['procedureevents'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_proto = tf.train.Example.FromString(serialized_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tr.record for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath_output = '/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/padded_arrays/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedccd2d5bdc41ffb576eb0c94057872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6472), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write the `tf.Example` observations to the file.\n",
    "filename = 'all_events_test.tfrecord'\n",
    "with tf.python_io.TFRecordWriter(mypath_output+filename) as writer:\n",
    "    for i in tqdm(range(len(df_test))):\n",
    "        \n",
    "        example = serialize_example(target = df_test['HOSPITAL_EXPIRE_FLAG'][i],\n",
    "                                    target2 = df_test['LOS'][i],\n",
    "                                    feature1 = pad_sequences([df_test['event'][i]], maxlen=pctl_999_dict['event'], dtype='int32', padding='post', truncating='pre', value=0)[0], \n",
    "                                    feature2 = pad_sequences([df_test['inputevents_cv'][i]], maxlen=pctl_999_dict['inputevents_cv'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature3 = pad_sequences([df_test['inputevents_mv'][i]], maxlen=pctl_999_dict['inputevents_mv'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature4 = pad_sequences([df_test['labevents'][i]], maxlen=pctl_999_dict['labevents'], dtype='int32', padding='post', truncating='pre', value=0)[0], \n",
    "                                    feature5 = pad_sequences([df_test['microbioevents'][i]], maxlen=pctl_999_dict['microbioevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature6 = pad_sequences([df_test['noteevents'][i]], maxlen=pctl_999_dict['noteevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature7 = pad_sequences([df_test['outputevents'][i]], maxlen=pctl_999_dict['outputevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature8 = pad_sequences([df_test['prescriptionevents'][i]], maxlen=pctl_999_dict['prescriptionevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature9 = pad_sequences([df_test['procedureevents'][i]], maxlen=pctl_999_dict['procedureevents'], dtype='int32', padding='post', truncating='pre', value=0)[0])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710dfba54ae34b9584680a71e5b29aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5410), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write the `tf.Example` observations to the file.\n",
    "filename = 'all_events_valid.tfrecord'\n",
    "with tf.python_io.TFRecordWriter(mypath_output+filename) as writer:\n",
    "    for i in tqdm(range(len(df_valid))):\n",
    "        \n",
    "        example = serialize_example(target = df_valid['HOSPITAL_EXPIRE_FLAG'][i],\n",
    "                                    target2 = df_valid['LOS'][i],\n",
    "                                    feature1 = pad_sequences([df_valid['event'][i]], maxlen=pctl_999_dict['event'], dtype='int32', padding='post', truncating='pre', value=0)[0], \n",
    "                                    feature2 = pad_sequences([df_valid['inputevents_cv'][i]], maxlen=pctl_999_dict['inputevents_cv'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature3 = pad_sequences([df_valid['inputevents_mv'][i]], maxlen=pctl_999_dict['inputevents_mv'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature4 = pad_sequences([df_valid['labevents'][i]], maxlen=pctl_999_dict['labevents'], dtype='int32', padding='post', truncating='pre', value=0)[0], \n",
    "                                    feature5 = pad_sequences([df_valid['microbioevents'][i]], maxlen=pctl_999_dict['microbioevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature6 = pad_sequences([df_valid['noteevents'][i]], maxlen=pctl_999_dict['noteevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature7 = pad_sequences([df_valid['outputevents'][i]], maxlen=pctl_999_dict['outputevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature8 = pad_sequences([df_valid['prescriptionevents'][i]], maxlen=pctl_999_dict['prescriptionevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature9 = pad_sequences([df_valid['procedureevents'][i]], maxlen=pctl_999_dict['procedureevents'], dtype='int32', padding='post', truncating='pre', value=0)[0])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce1b015079a4fe9a8c9c632cace5296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30936), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write the `tf.Example` observations to the file.\n",
    "filename = 'all_events_train.tfrecord'\n",
    "with tf.python_io.TFRecordWriter(mypath_output+filename) as writer:\n",
    "    for i in tqdm(range(len(df_train))):\n",
    "        \n",
    "        example = serialize_example(target = df_train['HOSPITAL_EXPIRE_FLAG'][i],\n",
    "                                    target2 = df_train['LOS'][i],\n",
    "                                    feature1 = pad_sequences([df_train['event'][i]], maxlen=pctl_999_dict['event'], dtype='int32', padding='post', truncating='pre', value=0)[0], \n",
    "                                    feature2 = pad_sequences([df_train['inputevents_cv'][i]], maxlen=pctl_999_dict['inputevents_cv'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature3 = pad_sequences([df_train['inputevents_mv'][i]], maxlen=pctl_999_dict['inputevents_mv'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature4 = pad_sequences([df_train['labevents'][i]], maxlen=pctl_999_dict['labevents'], dtype='int32', padding='post', truncating='pre', value=0)[0], \n",
    "                                    feature5 = pad_sequences([df_train['microbioevents'][i]], maxlen=pctl_999_dict['microbioevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature6 = pad_sequences([df_train['noteevents'][i]], maxlen=pctl_999_dict['noteevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature7 = pad_sequences([df_train['outputevents'][i]], maxlen=pctl_999_dict['outputevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature8 = pad_sequences([df_train['prescriptionevents'][i]], maxlen=pctl_999_dict['prescriptionevents'], dtype='int32', padding='post', truncating='pre', value=0)[0],\n",
    "                                    feature9 = pad_sequences([df_train['procedureevents'][i]], maxlen=pctl_999_dict['procedureevents'], dtype='int32', padding='post', truncating='pre', value=0)[0])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
