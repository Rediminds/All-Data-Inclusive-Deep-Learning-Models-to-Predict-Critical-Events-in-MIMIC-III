{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath_input = '../../datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/all_events.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath_output = \"/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/padded_arrays/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(mypath_input).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'events':'event'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>event</th>\n",
       "      <th>inputevents_cv</th>\n",
       "      <th>inputevents_mv</th>\n",
       "      <th>labevents</th>\n",
       "      <th>microbioevents</th>\n",
       "      <th>noteevents</th>\n",
       "      <th>outputevents</th>\n",
       "      <th>prescriptionevents</th>\n",
       "      <th>procedureevents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163353</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Resp, Rate, 3603-39-Breath, Resp, Rate, 3603-...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Atypical, Lymphocytes, Blood, Hematology, 511...</td>\n",
       "      <td>[BLOOD, CULTURE, -, NEONATE, Negative, Culture]</td>\n",
       "      <td>[Nursing/other, Report, Nursing, Transfer, not...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[MAIN, NEOIVGentamicin, NaN, DRUG_CD-GENT10I, ...</td>\n",
       "      <td>[NaN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145834</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Sputum, Source, 657-Suctioned, Riker, SAS, Sc...</td>\n",
       "      <td>[D5W, Intravenous, Push, 30013-250-ml, D5W, In...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Anion, Gap, Blood, Chemistry, 50868-17-mEq/L,...</td>\n",
       "      <td>[SWAB, PROBABLE, ENTEROCOCCUS, SWAB, YEAST, SW...</td>\n",
       "      <td>[Echo, Report, PATIENT/TEST, INFORMATION:, Ind...</td>\n",
       "      <td>[Urine, Out, Foley, 40055-20-ml, Urine, Out, F...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[NaN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  HOSPITAL_EXPIRE_FLAG  SUBJECT_ID  \\\n",
       "0   163353                     0           2   \n",
       "1   145834                     0           3   \n",
       "\n",
       "                                               event  \\\n",
       "0  [Resp, Rate, 3603-39-Breath, Resp, Rate, 3603-...   \n",
       "1  [Sputum, Source, 657-Suctioned, Riker, SAS, Sc...   \n",
       "\n",
       "                                      inputevents_cv inputevents_mv  \\\n",
       "0                                              [NaN]          [NaN]   \n",
       "1  [D5W, Intravenous, Push, 30013-250-ml, D5W, In...          [NaN]   \n",
       "\n",
       "                                           labevents  \\\n",
       "0  [Atypical, Lymphocytes, Blood, Hematology, 511...   \n",
       "1  [Anion, Gap, Blood, Chemistry, 50868-17-mEq/L,...   \n",
       "\n",
       "                                      microbioevents  \\\n",
       "0    [BLOOD, CULTURE, -, NEONATE, Negative, Culture]   \n",
       "1  [SWAB, PROBABLE, ENTEROCOCCUS, SWAB, YEAST, SW...   \n",
       "\n",
       "                                          noteevents  \\\n",
       "0  [Nursing/other, Report, Nursing, Transfer, not...   \n",
       "1  [Echo, Report, PATIENT/TEST, INFORMATION:, Ind...   \n",
       "\n",
       "                                        outputevents  \\\n",
       "0                                              [NaN]   \n",
       "1  [Urine, Out, Foley, 40055-20-ml, Urine, Out, F...   \n",
       "\n",
       "                                  prescriptionevents procedureevents  \n",
       "0  [MAIN, NEOIVGentamicin, NaN, DRUG_CD-GENT10I, ...           [NaN]  \n",
       "1                                              [NaN]           [NaN]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>event</th>\n",
       "      <th>inputevents_cv</th>\n",
       "      <th>inputevents_mv</th>\n",
       "      <th>labevents</th>\n",
       "      <th>microbioevents</th>\n",
       "      <th>noteevents</th>\n",
       "      <th>outputevents</th>\n",
       "      <th>prescriptionevents</th>\n",
       "      <th>procedureevents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>134748</td>\n",
       "      <td>1</td>\n",
       "      <td>1744</td>\n",
       "      <td>[RU, Strength/Movement, 596-Moves on Bed, Reas...</td>\n",
       "      <td>[D5W, Intravenous, Push, 30013-50-ml, D5W, Int...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Bacteria, Urine, Hematology, Bilirubin, Urine...</td>\n",
       "      <td>[BLOOD, CULTURE, Negative, Culture, BLOOD, CUL...</td>\n",
       "      <td>[ECG, Report, Sinus, rhythm, Nondiagnostic, la...</td>\n",
       "      <td>[Pre-Admission, Output, Pre-Admission, Output,...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[NaN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139336</td>\n",
       "      <td>1</td>\n",
       "      <td>17224</td>\n",
       "      <td>[Ectopy, Type, 161-None, Skin, Integrity, 644-...</td>\n",
       "      <td>[.9%, Normal, Saline, Intravenous, Push, 30018...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Acetaminophen, Blood, Chemistry, Anion, Gap, ...</td>\n",
       "      <td>[BLOOD, CULTURE, Negative, Culture, URINE, Neg...</td>\n",
       "      <td>[Discharge, summary, Report, Admission, Date:,...</td>\n",
       "      <td>[Pre-Admission, Output, Pre-Admission, Output,...</td>\n",
       "      <td>[MAIN, Heparin, Flush, CVL, 100, units/ml, Hep...</td>\n",
       "      <td>[NaN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HADM_ID  HOSPITAL_EXPIRE_FLAG  SUBJECT_ID  \\\n",
       "20   134748                     1        1744   \n",
       "21   139336                     1       17224   \n",
       "\n",
       "                                                event  \\\n",
       "20  [RU, Strength/Movement, 596-Moves on Bed, Reas...   \n",
       "21  [Ectopy, Type, 161-None, Skin, Integrity, 644-...   \n",
       "\n",
       "                                       inputevents_cv inputevents_mv  \\\n",
       "20  [D5W, Intravenous, Push, 30013-50-ml, D5W, Int...          [NaN]   \n",
       "21  [.9%, Normal, Saline, Intravenous, Push, 30018...          [NaN]   \n",
       "\n",
       "                                            labevents  \\\n",
       "20  [Bacteria, Urine, Hematology, Bilirubin, Urine...   \n",
       "21  [Acetaminophen, Blood, Chemistry, Anion, Gap, ...   \n",
       "\n",
       "                                       microbioevents  \\\n",
       "20  [BLOOD, CULTURE, Negative, Culture, BLOOD, CUL...   \n",
       "21  [BLOOD, CULTURE, Negative, Culture, URINE, Neg...   \n",
       "\n",
       "                                           noteevents  \\\n",
       "20  [ECG, Report, Sinus, rhythm, Nondiagnostic, la...   \n",
       "21  [Discharge, summary, Report, Admission, Date:,...   \n",
       "\n",
       "                                         outputevents  \\\n",
       "20  [Pre-Admission, Output, Pre-Admission, Output,...   \n",
       "21  [Pre-Admission, Output, Pre-Admission, Output,...   \n",
       "\n",
       "                                   prescriptionevents procedureevents  \n",
       "20                                              [NaN]           [NaN]  \n",
       "21  [MAIN, Heparin, Flush, CVL, 100, units/ml, Hep...           [NaN]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['HOSPITAL_EXPIRE_FLAG']==1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ICUTAYS.csv\n",
    "df_icu =  pd.read_csv('../../datasets/raw/ICUSTAYS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>FIRST_CAREUNIT</th>\n",
       "      <th>LAST_CAREUNIT</th>\n",
       "      <th>FIRST_WARDID</th>\n",
       "      <th>LAST_WARDID</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>OUTTIME</th>\n",
       "      <th>LOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365</td>\n",
       "      <td>268</td>\n",
       "      <td>110404</td>\n",
       "      <td>280836</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2198-02-14 23:27:38</td>\n",
       "      <td>2198-02-18 05:26:11</td>\n",
       "      <td>3.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366</td>\n",
       "      <td>269</td>\n",
       "      <td>106296</td>\n",
       "      <td>206613</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2170-11-05 11:05:29</td>\n",
       "      <td>2170-11-08 17:46:57</td>\n",
       "      <td>3.2788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367</td>\n",
       "      <td>270</td>\n",
       "      <td>188028</td>\n",
       "      <td>220345</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>CCU</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>2128-06-24 15:05:20</td>\n",
       "      <td>2128-06-27 12:32:29</td>\n",
       "      <td>2.8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>368</td>\n",
       "      <td>271</td>\n",
       "      <td>173727</td>\n",
       "      <td>249196</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>SICU</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>2120-08-07 23:12:42</td>\n",
       "      <td>2120-08-10 00:39:04</td>\n",
       "      <td>2.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>272</td>\n",
       "      <td>164716</td>\n",
       "      <td>210407</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>CCU</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>2186-12-25 21:08:04</td>\n",
       "      <td>2186-12-27 12:01:13</td>\n",
       "      <td>1.6202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  ICUSTAY_ID DBSOURCE FIRST_CAREUNIT  \\\n",
       "0     365         268   110404      280836  carevue           MICU   \n",
       "1     366         269   106296      206613  carevue           MICU   \n",
       "2     367         270   188028      220345  carevue            CCU   \n",
       "3     368         271   173727      249196  carevue           MICU   \n",
       "4     369         272   164716      210407  carevue            CCU   \n",
       "\n",
       "  LAST_CAREUNIT  FIRST_WARDID  LAST_WARDID               INTIME  \\\n",
       "0          MICU            52           52  2198-02-14 23:27:38   \n",
       "1          MICU            52           52  2170-11-05 11:05:29   \n",
       "2           CCU            57           57  2128-06-24 15:05:20   \n",
       "3          SICU            52           23  2120-08-07 23:12:42   \n",
       "4           CCU            57           57  2186-12-25 21:08:04   \n",
       "\n",
       "               OUTTIME     LOS  \n",
       "0  2198-02-18 05:26:11  3.2490  \n",
       "1  2170-11-08 17:46:57  3.2788  \n",
       "2  2128-06-27 12:32:29  2.8939  \n",
       "3  2120-08-10 00:39:04  2.0600  \n",
       "4  2186-12-27 12:01:13  1.6202  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping ICUstays with LOS<1\n",
    "df_icu = df_icu[df_icu['LOS'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53482"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.HADM_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['HADM_ID'].isin(df_icu['HADM_ID'].unique())]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_icu[['HADM_ID','LOS']], how='left',left_on='HADM_ID', right_on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>event</th>\n",
       "      <th>inputevents_cv</th>\n",
       "      <th>inputevents_mv</th>\n",
       "      <th>labevents</th>\n",
       "      <th>microbioevents</th>\n",
       "      <th>noteevents</th>\n",
       "      <th>outputevents</th>\n",
       "      <th>prescriptionevents</th>\n",
       "      <th>procedureevents</th>\n",
       "      <th>LOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145834</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Sputum, Source, 657-Suctioned, Riker, SAS, Sc...</td>\n",
       "      <td>[D5W, Intravenous, Push, 30013-250-ml, D5W, In...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Anion, Gap, Blood, Chemistry, 50868-17-mEq/L,...</td>\n",
       "      <td>[SWAB, PROBABLE, ENTEROCOCCUS, SWAB, YEAST, SW...</td>\n",
       "      <td>[Echo, Report, PATIENT/TEST, INFORMATION:, Ind...</td>\n",
       "      <td>[Urine, Out, Foley, 40055-20-ml, Urine, Out, F...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>6.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185483</td>\n",
       "      <td>0</td>\n",
       "      <td>9078</td>\n",
       "      <td>[Riker, SAS, Scale, 1337-Sedated, Riker, SAS, ...</td>\n",
       "      <td>[D5W, Intravenous, Push, 30013-250-ml, D5W, In...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Eosinophils, Blood, Hematology, 51200-0-%, He...</td>\n",
       "      <td>[SPUTUM, YEAST, BLOOD, CULTURE, Negative, Cult...</td>\n",
       "      <td>[ECG, Report, Atrial, fibrillation, Inferior, ...</td>\n",
       "      <td>[Gastric, Nasogastric, 40052-150-ml, Pre-Admis...</td>\n",
       "      <td>[MAIN, Potassium, Phosphate, NaN, DRUG_CD-KPHO...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>9.7236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167537</td>\n",
       "      <td>0</td>\n",
       "      <td>9162</td>\n",
       "      <td>[RU, Strength/Movement, 596-Normal Strength, R...</td>\n",
       "      <td>[D5W, Intravenous, Push, 30013-250-ml, .9%, No...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Acetaminophen, Blood, Chemistry, Amylase, Blo...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Radiology, CT, HEAD, W/O, CONTRAST, 7:24, PM,...</td>\n",
       "      <td>[Urine, Out, Foley, 40055-120-ml, Urine, Out, ...</td>\n",
       "      <td>[MAIN, Insulin, Insulin, -, Sliding, Scale, DR...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>1.8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>9895</td>\n",
       "      <td>[Assistance, Device, 54-1 Person Assist, RUL, ...</td>\n",
       "      <td>[Po, Intake, Oral, 30056-120-ml, Po, Intake, O...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[Calculated, Total, CO2, Blood, Blood, Gas, 50...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[ECG, Report, Sinus, tachycardia, Left, axis, ...</td>\n",
       "      <td>[Urine, Out, Void, 40069-400-ml, Urine, Out, V...</td>\n",
       "      <td>[MAIN, Azithromycin, Azithromycin, DRUG_CD-ZIT...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>4.9776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135351</td>\n",
       "      <td>0</td>\n",
       "      <td>17213</td>\n",
       "      <td>[Color, Overall, 3373-Pink, Bowel, Sounds, 80-...</td>\n",
       "      <td>[E, 20, FS, PO, By, Mouth, 30270-30-ml, E, 20,...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[MCV, Blood, Hematology, 51250-107-fL, abnorma...</td>\n",
       "      <td>[BLOOD, CULTURE, -, NEONATE, Negative, Culture]</td>\n",
       "      <td>[Nursing/other, Report, Attending, Note, Day, ...</td>\n",
       "      <td>[Urine, ., 43175-3-ml, Urine, ., 43175-2-ml, U...</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>[NaN]</td>\n",
       "      <td>1.9599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  HOSPITAL_EXPIRE_FLAG  SUBJECT_ID  \\\n",
       "0   145834                     0           3   \n",
       "1   185483                     0        9078   \n",
       "2   167537                     0        9162   \n",
       "3   100006                     0        9895   \n",
       "4   135351                     0       17213   \n",
       "\n",
       "                                               event  \\\n",
       "0  [Sputum, Source, 657-Suctioned, Riker, SAS, Sc...   \n",
       "1  [Riker, SAS, Scale, 1337-Sedated, Riker, SAS, ...   \n",
       "2  [RU, Strength/Movement, 596-Normal Strength, R...   \n",
       "3  [Assistance, Device, 54-1 Person Assist, RUL, ...   \n",
       "4  [Color, Overall, 3373-Pink, Bowel, Sounds, 80-...   \n",
       "\n",
       "                                      inputevents_cv inputevents_mv  \\\n",
       "0  [D5W, Intravenous, Push, 30013-250-ml, D5W, In...          [NaN]   \n",
       "1  [D5W, Intravenous, Push, 30013-250-ml, D5W, In...          [NaN]   \n",
       "2  [D5W, Intravenous, Push, 30013-250-ml, .9%, No...          [NaN]   \n",
       "3  [Po, Intake, Oral, 30056-120-ml, Po, Intake, O...          [NaN]   \n",
       "4  [E, 20, FS, PO, By, Mouth, 30270-30-ml, E, 20,...          [NaN]   \n",
       "\n",
       "                                           labevents  \\\n",
       "0  [Anion, Gap, Blood, Chemistry, 50868-17-mEq/L,...   \n",
       "1  [Eosinophils, Blood, Hematology, 51200-0-%, He...   \n",
       "2  [Acetaminophen, Blood, Chemistry, Amylase, Blo...   \n",
       "3  [Calculated, Total, CO2, Blood, Blood, Gas, 50...   \n",
       "4  [MCV, Blood, Hematology, 51250-107-fL, abnorma...   \n",
       "\n",
       "                                      microbioevents  \\\n",
       "0  [SWAB, PROBABLE, ENTEROCOCCUS, SWAB, YEAST, SW...   \n",
       "1  [SPUTUM, YEAST, BLOOD, CULTURE, Negative, Cult...   \n",
       "2                                              [NaN]   \n",
       "3                                              [NaN]   \n",
       "4    [BLOOD, CULTURE, -, NEONATE, Negative, Culture]   \n",
       "\n",
       "                                          noteevents  \\\n",
       "0  [Echo, Report, PATIENT/TEST, INFORMATION:, Ind...   \n",
       "1  [ECG, Report, Atrial, fibrillation, Inferior, ...   \n",
       "2  [Radiology, CT, HEAD, W/O, CONTRAST, 7:24, PM,...   \n",
       "3  [ECG, Report, Sinus, tachycardia, Left, axis, ...   \n",
       "4  [Nursing/other, Report, Attending, Note, Day, ...   \n",
       "\n",
       "                                        outputevents  \\\n",
       "0  [Urine, Out, Foley, 40055-20-ml, Urine, Out, F...   \n",
       "1  [Gastric, Nasogastric, 40052-150-ml, Pre-Admis...   \n",
       "2  [Urine, Out, Foley, 40055-120-ml, Urine, Out, ...   \n",
       "3  [Urine, Out, Void, 40069-400-ml, Urine, Out, V...   \n",
       "4  [Urine, ., 43175-3-ml, Urine, ., 43175-2-ml, U...   \n",
       "\n",
       "                                  prescriptionevents procedureevents     LOS  \n",
       "0                                              [NaN]           [NaN]  6.0646  \n",
       "1  [MAIN, Potassium, Phosphate, NaN, DRUG_CD-KPHO...           [NaN]  9.7236  \n",
       "2  [MAIN, Insulin, Insulin, -, Sliding, Scale, DR...           [NaN]  1.8494  \n",
       "3  [MAIN, Azithromycin, Azithromycin, DRUG_CD-ZIT...           [NaN]  4.9776  \n",
       "4                                              [NaN]           [NaN]  1.9599  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records with LOS missing\n",
    "df = df[df['LOS'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary LOS i.e. >7 or 7\n",
    "df['LOS'] = df['LOS'].map(lambda x: 0 if x < 7 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients 35348\n",
      "number of admissions 42818\n",
      "number of in-hospital mortality 4146\n",
      "patient with atleast 7 days icu stay 8450\n"
     ]
    }
   ],
   "source": [
    "print(\"number of patients {}\".format(len(df.SUBJECT_ID.unique())))\n",
    "print(\"number of admissions {}\".format(len(df.HADM_ID.unique())))\n",
    "print(\"number of in-hospital mortality {}\".format(sum(df['HOSPITAL_EXPIRE_FLAG'])))\n",
    "print('patient with atleast 7 days icu stay {}'.format(sum(df['LOS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25538 4507 5303\n"
     ]
    }
   ],
   "source": [
    "#split SubjectID into train/valid/test\n",
    "X_train, X_test = train_test_split(df.SUBJECT_ID.unique(),test_size=0.15, random_state=1234)\n",
    "\n",
    "X_train, X_valid = train_test_split(X_train,test_size=0.15, random_state=1234)\n",
    "\n",
    "print(len(X_train),len(X_valid),len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export the list of hospital admission id for train , valid, test\n",
    "# Save SUBJECT_ID for training data\n",
    "import json\n",
    "with open(mypath_output+'trainlist_SUBJECT_ID.json', 'w') as filehandle:\n",
    "    json.dump(X_train.tolist(), filehandle)\n",
    "    \n",
    "# Save HADM_ID for training data\n",
    "import json\n",
    "with open(mypath_output+'validlist_SUBJECT_ID.json', 'w') as filehandle:\n",
    "    json.dump(X_valid.tolist(), filehandle)\n",
    "\n",
    "# Save HADM_ID for training data\n",
    "import json\n",
    "with open(mypath_output+'testlist_SUBJECT_ID.json', 'w') as filehandle:\n",
    "    json.dump(X_test.tolist(), filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of in-hospital mortality in train, valid and test are 0.12 0.12 0.12\n"
     ]
    }
   ],
   "source": [
    "print(\"The ratio of in-hospital mortality in train, valid and test are {:.2} {:.2} {:.2}\".format(\n",
    "    sum(df[df.SUBJECT_ID.isin(X_train)]['HOSPITAL_EXPIRE_FLAG'])/len(X_train),\n",
    "    sum(df[df.SUBJECT_ID.isin(X_valid)]['HOSPITAL_EXPIRE_FLAG'])/len(X_valid),\n",
    "    sum(df[df.SUBJECT_ID.isin(X_test)]['HOSPITAL_EXPIRE_FLAG'])/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of icustays atleast 7 days in train, valid and test are 0.24 0.24 0.24\n"
     ]
    }
   ],
   "source": [
    "print(\"The ratio of icustays atleast 7 days in train, valid and test are {:.2} {:.2} {:.2}\".format(\n",
    "    sum(df[df.SUBJECT_ID.isin(X_train)]['LOS'])/len(X_train),\n",
    "    sum(df[df.SUBJECT_ID.isin(X_valid)]['LOS'])/len(X_valid),\n",
    "    sum(df[df.SUBJECT_ID.isin(X_test)]['LOS'])/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes input as a pd.series of lists and determines longest length of a list in the series\n",
    "def cal_max_len(x):\n",
    "    a = []\n",
    "    for i in range(len(x)):\n",
    "        a.append(len(x[i]))\n",
    "    max_len = int(max(a))\n",
    "    pctl_999 = int(np.percentile(a, 99.9))\n",
    "    return max_len, pctl_999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to hold max length of list in each column\n",
    "max_len_dict = {}\n",
    "pctl_999_dict = {}\n",
    "for i in df.columns:\n",
    "    if 'event' in i:\n",
    "        max_len_dict.update({i:cal_max_len(df[i])[0]})\n",
    "        pctl_999_dict.update({i:cal_max_len(df[i])[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': 24791,\n",
       " 'inputevents_cv': 8325,\n",
       " 'inputevents_mv': 11623,\n",
       " 'labevents': 24991,\n",
       " 'microbioevents': 1502,\n",
       " 'noteevents': 32149,\n",
       " 'outputevents': 1153,\n",
       " 'prescriptionevents': 7271,\n",
       " 'procedureevents': 246}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': 11206,\n",
       " 'inputevents_cv': 2472,\n",
       " 'inputevents_mv': 2747,\n",
       " 'labevents': 6534,\n",
       " 'microbioevents': 348,\n",
       " 'noteevents': 19420,\n",
       " 'outputevents': 433,\n",
       " 'prescriptionevents': 2525,\n",
       " 'procedureevents': 144}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pctl_999_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'microbioevents': 1502, 'inputevents_mv': 11623, 'prescriptionevents': 7271, 'outputevents': 1153, 'inputevents_cv': 8325, 'procedureevents': 246, 'noteevents': 32149, 'event': 24791, 'labevents': 24991}\n"
     ]
    }
   ],
   "source": [
    "print(max_len_dict)\n",
    "# Save dict containing max length of each event type for training data\n",
    "import json\n",
    "with open(mypath_output+'max_padlen_dict.json', 'w') as filehandle:\n",
    "    json.dump(max_len_dict, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'microbioevents': 348, 'inputevents_mv': 2747, 'prescriptionevents': 2525, 'outputevents': 433, 'inputevents_cv': 2472, 'procedureevents': 144, 'noteevents': 19420, 'event': 11206, 'labevents': 6534}\n"
     ]
    }
   ],
   "source": [
    "pctl_999_dict\n",
    "print(pctl_999_dict)\n",
    "# Save dict containing 99.9 pctl length of each event type for training data\n",
    "import json\n",
    "with open(mypath_output+'pctl999_padlen_dict.json', 'w') as filehandle:\n",
    "    json.dump(pctl_999_dict, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit Tokenizer for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, valid, test Dataset\n",
    "df_train = df[df.SUBJECT_ID.isin(X_train)].reset_index(drop = True)\n",
    "df_valid = df[df.SUBJECT_ID.isin(X_valid)].reset_index(drop = True)\n",
    "df_test = df[df.SUBJECT_ID.isin(X_test)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output path\n",
    "tokenizer_path = \"/home/jupyter/output/tokenizer/\"\n",
    "import os\n",
    "os.makedirs(tokenizer_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer built for event\n",
      "Tokenizer built for inputevents_cv\n",
      "Tokenizer built for inputevents_mv\n",
      "Tokenizer built for labevents\n",
      "Tokenizer built for microbioevents\n",
      "Tokenizer built for noteevents\n",
      "Tokenizer built for outputevents\n",
      "Tokenizer built for prescriptionevents\n",
      "Tokenizer built for procedureevents\n",
      "All tokenizers are built\n",
      "CPU times: user 4min 33s, sys: 528 ms, total: 4min 33s\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Training tokenizers on train dataset\n",
    "tokenizer_dict = {} \n",
    "for i in df.columns:\n",
    "    if 'event' in i:\n",
    "        # initiate tokenizer\n",
    "        t = Tokenizer(lower=True,split=',', filters= '')\n",
    "        # Fit tokenizer on event\n",
    "        t.fit_on_texts(df_train[i])\n",
    "        tokenizer_dict.update({i:t})\n",
    "        print(\"Tokenizer built for {}\".format(i))\n",
    "print('All tokenizers are built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the Chartevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_chartevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['event'],handle)  \n",
    "    \n",
    "#saving the Inputevents_cv tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_inputevents_cv.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['inputevents_cv'],handle) \n",
    "    \n",
    "#saving the Inputevents_mv tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_inputevents_mv.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['inputevents_mv'],handle) \n",
    "\n",
    "#saving the Labevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_labevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['labevents'],handle) \n",
    "    \n",
    "#saving the Microbioevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_microbioevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['microbioevents'],handle) \n",
    "    \n",
    "#saving the Notevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_noteevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['noteevents'],handle) \n",
    "\n",
    "#saving the Outputevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_outputevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['outputevents'],handle) \n",
    "\n",
    "#saving the Prescriptionevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_prescriptionevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['prescriptionevents'],handle) \n",
    "    \n",
    "#saving the Procedureevents tokenizer to disk\n",
    "with open(tokenizer_path+\"tokenizer_procedureevents.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer_dict['procedureevents'],handle) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer Encode Train Data, Valid Data, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove low count words from tokenizer\n",
    "def tokenizer_low_count(tokenizer):\n",
    "    t = tokenizer\n",
    "    #initialize unknown token\n",
    "    t.oov_token = 'UNK'\n",
    "    # add \"UNK\" token and an integer value for it to the tokenizer word index\n",
    "    t.word_index.update({'UNK':len(t.word_index)+1})\n",
    "    # Create a list of tokens that occur only once\n",
    "    low_count_words = []\n",
    "    for k,v in t.word_counts.items():\n",
    "        if v==1:\n",
    "            low_count_words.append(k)\n",
    "    #Removed words with low count from tokenizer\n",
    "    for w in low_count_words:\n",
    "        del t.word_index[w]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_procedureevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle)\n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['procedureevents'] = df_train['procedureevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['procedureevents'] = df_valid['procedureevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['procedureevents'] = df_test['procedureevents'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_chartevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['event'] = df_train['event'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['event'] = df_valid['event'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['event'] = df_test['event'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_inputevents_cv.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['inputevents_cv'] = df_train['inputevents_cv'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['inputevents_cv'] = df_valid['inputevents_cv'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['inputevents_cv'] = df_test['inputevents_cv'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_inputevents_mv.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['inputevents_mv'] = df_train['inputevents_mv'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['inputevents_mv'] = df_valid['inputevents_mv'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['inputevents_mv'] = df_test['inputevents_mv'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_labevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['labevents'] = df_train['labevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['labevents'] = df_valid['labevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['labevents'] = df_test['labevents'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_microbioevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['microbioevents'] = df_train['microbioevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['microbioevents'] = df_valid['microbioevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['microbioevents'] = df_test['microbioevents'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_noteevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['noteevents'] = df_train['noteevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['noteevents'] = df_valid['noteevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['noteevents'] = df_test['noteevents'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_outputevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['outputevents'] = df_train['outputevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['outputevents'] = df_valid['outputevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['outputevents'] = df_test['outputevents'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer form disk\n",
    "with open(tokenizer_path+\"tokenizer_prescriptionevents.pickle\", 'rb') as handle:\n",
    "    t = pickle.load(handle) \n",
    "\n",
    "# Removing tokens with low count\n",
    "tokenizer_low_count(t)\n",
    "\n",
    "# replacing tokens with their integer codes\n",
    "df_train['prescriptionevents'] = df_train['prescriptionevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_valid['prescriptionevents'] = df_valid['prescriptionevents'].map(lambda y: t.texts_to_sequences([y])[0])\n",
    "df_test['prescriptionevents'] = df_test['prescriptionevents'].map(lambda y: t.texts_to_sequences([y])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the integer encoded data to disk\n",
    "# create output path\n",
    "file_save_path = '/home/jupyter/datasets/training_data/data_before_24hrs_icu/data_grouped_HADM_ID/train_test_valid/'\n",
    "import os\n",
    "os.makedirs(file_save_path, exist_ok=True)\n",
    "# export the dataframe to JSON format\n",
    "df_train.to_json(file_save_path+\"all_events_train.json\",orient = 'records')\n",
    "df_valid.to_json(file_save_path+\"all_events_valid.json\",orient = 'records') \n",
    "df_test.to_json(file_save_path+\"all_events_test.json\",orient = 'records') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
