{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impor packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of raw data files\n",
    "input_path = \"/home/jupyter/datasets/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read LABEVENTS.csv file\n",
    "df = pd.read_csv(filepath_or_buffer=input_path+'INPUTEVENTS_MV.csv',dtype = \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read D_ITEMS.csv file\n",
    "df1 = pd.read_csv(filepath_or_buffer=input_path+'D_ITEMS.csv',dtype = \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the labels for ITEMD \n",
    "df=df.merge(df1[['ITEMID','LABEL']], how='left', left_on='ITEMID', right_on='ITEMID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print datatype and non-null data points for each column\n",
    "df.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Row_ID \n",
    "df = df.drop(labels='ROW_ID',axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping redundant columns\n",
    "df = df.drop(labels=['STARTTIME','ENDTIME','COMMENTS_EDITEDBY','COMMENTS_CANCELEDBY','COMMENTS_DATE','CGID','ORDERID','LINKORDERID','ISOPENBAG','CONTINUEINNEXTDEPT','CANCELREASON','ORIGINALAMOUNT','ORIGINALRATE'],axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print datatype and non-null data points for each column\n",
    "df.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ITEMID, VALUE, UOM into single token\n",
    "df['AMOUNT_VALUE_UOM'] = df['ITEMID']+'-'+df['AMOUNT']+'-'+df['AMOUNTUOM']\n",
    "df['RATE_VALUE_UOM'] = df['ITEMID']+'-'+df['RATE']+'-'+df['RATEUOM']\n",
    "df['FLUID_VALUE_UOM'] = 'FLUID'+'-'+df['TOTALAMOUNT']+'-'+df['TOTALAMOUNTUOM']\n",
    "df['PATIENTWEIGHT'] = 'WEIGHT'+'-'+df['PATIENTWEIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if value if missing then replace merge tokens with 'NaN'\n",
    "df.loc[df['AMOUNT']=='NaN','AMOUNT_VALUE_UOM'] = 'NaN'\n",
    "df.loc[df['RATE']=='NaN','RATE_VALUE_UOM'] = 'NaN'\n",
    "df.loc[df['TOTALAMOUNT']=='NaN','FLUID_VALUE_UOM'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns\n",
    "df = df.drop(labels=['ITEMID','AMOUNT','AMOUNTUOM','RATE','RATEUOM','TOTALAMOUNT','TOTALAMOUNTUOM','PATIENTWEIGHT'],axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removce any speacial charecters from the free text columns\n",
    "df['ORDERCATEGORYNAME'] = df['ORDERCATEGORYNAME'].map(lambda x : re.sub('[!\"#$%&()*+,;<=>?@[\\]^_`{|}~\\n]', '', x)) \n",
    "\n",
    "df['SECONDARYORDERCATEGORYNAME'] = df['SECONDARYORDERCATEGORYNAME'].map(lambda x : re.sub('[!\"#$%&()*+,;<=>?@[\\]^_`{|}~\\n]', '', x)) \n",
    "\n",
    "df['ORDERCOMPONENTTYPEDESCRIPTION'] = df['ORDERCOMPONENTTYPEDESCRIPTION'].map(lambda x : re.sub('[!\"#$%&()*+,;<=>?@[\\]^_`{|}~\\n]', '', x))\n",
    "\n",
    "df['ORDERCATEGORYDESCRIPTION'] = df['ORDERCATEGORYDESCRIPTION'].map(lambda x : re.sub('[!\"#$%&()*+,;<=>?@[\\]^_`{|}~\\n]', '', x))\n",
    "\n",
    "df['STATUSDESCRIPTION'] = df['STATUSDESCRIPTION'].map(lambda x : re.sub('[!\"#$%&()*+,;<=>?@[\\]^_`{|}~\\n]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputevents_mv by mergeing all the columns on whitespace\n",
    "df['inputevents_mv'] = df['LABEL']+' '+df['ORDERCATEGORYNAME']+' '+df['SECONDARYORDERCATEGORYNAME']+' '+df['ORDERCOMPONENTTYPEDESCRIPTION']+' '+df['ORDERCATEGORYDESCRIPTION']+' '+df['STATUSDESCRIPTION']+' '+df['AMOUNT_VALUE_UOM']+' '+df['RATE_VALUE_UOM']+' '+df['FLUID_VALUE_UOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant columns\n",
    "df = df.drop(labels=['LABEL','ORDERCATEGORYNAME','SECONDARYORDERCATEGORYNAME','ORDERCOMPONENTTYPEDESCRIPTION','ORDERCATEGORYDESCRIPTION','STATUSDESCRIPTION','AMOUNT_VALUE_UOM','RATE_VALUE_UOM','FLUID_VALUE_UOM'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on white spaceand convert tp list\n",
    "df['inputevents_mv'] = df['inputevents_mv'].map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'NaN' from the inputevents_mv\n",
    "df['inputevents_mv'] = df['inputevents_mv'].map(lambda x: list(filter(lambda a: a!='NaN',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output path\n",
    "mypath_output = \"/home/jupyter/datasets/inputevents_mv/tokenized/\"\n",
    "import os\n",
    "os.makedirs(mypath_output, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe to JSON format\n",
    "df.to_json(mypath_output+\"inputevents_mv.json\",orient = 'records') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
